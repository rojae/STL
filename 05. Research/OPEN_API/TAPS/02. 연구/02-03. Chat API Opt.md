# OpenAI Chat API 요청 파라미터 설명 (한글)

---

## ✅ 주요 파라미터 설명

### 🔹 model
- 사용할 모델 ID를 지정합니다.
- 예: `gpt-3.5-turbo` (기본값), `gpt-4` 등

### 🔹 messages
- 대화 이력을 리스트 형태로 전달합니다.
- 각 메시지는 다음 필드를 가집니다:
  - `role`: `system`, `user`, `assistant` 중 하나
  - `content`: 메시지의 텍스트 내용

#### 예시 구조:
```json
"messages": [
  { "role": "system", "content": "당신은 친절한 블로그 작가입니다." },
  { "role": "user", "content": "GPT-4는 어떤 기능이 있어?" },
  { "role": "assistant", "content": "GPT-4는 다음과 같은 기능이 있습니다..." }
]
```

---

### 🔹 temperature
- 0 ~ 2 사이의 값
- 창의성 조절. `0`에 가까울수록 결정적(deterministic), `1` 이상은 창의적이고 다양한 응답 가능

### 🔹 top_p
- 확률 누적값 기반의 단어 선택 제한 (0~1)
- `0.9`라면 상위 90% 확률 내에서만 단어 선택 → 더 정제된 결과

### 🔹 n
- 응답 개수 (동시에 몇 개의 응답을 받을지)

### 🔹 stream
- 스트리밍 응답 여부
- `true`로 설정 시 응답이 실시간 스트리밍(text/event-stream 형식)으로 전달됨

### 🔹 stop
- 응답을 중단할 단어나 구절을 지정

### 🔹 max_tokens
- 응답의 최대 토큰 수 제한

### 🔹 presence_penalty
- -2 ~ 2
- 새로운 주제를 유도 (중복 억제), 값이 클수록 새로운 단어 사용 유도

### 🔹 frequency_penalty
- -2 ~ 2
- 같은 단어 반복을 줄임

### 🔹 logit_bias
- 특정 토큰(단어)의 출현 확률을 조정
- 예: `{ 27000: -100 }` → 해당 토큰 완전 배제

### 🔹 user
- 사용자 식별자. OpenAI 로그에 기록되는 용도 (선택 사항)

---

📌 `presence_penalty`와 `frequency_penalty`는 유사하지만,
- `presence_penalty`는 "처음 등장 여부" 중심
- `frequency_penalty`는 "빈도(횟수)" 중심입니다.